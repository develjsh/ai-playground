# Scratch Neural Network

이 프로젝트는 파이썬과 numpy만 사용하여 XOR 문제를 해결하는 간단한 신경망을 처음부터 직접 구현하는 예제입니다.

## 주요 내용

- 1개의 은닉층을 가진 신경망 구조
- 순전파, 역전파, 가중치 업데이트를 모두 직접 구현
- XOR 데이터셋을 사용하여 학습 및 예측

## 파일 설명

- `scratch_nn.py` : 신경망 학습 및 예측 전체 코드

## 실행 환경

- Python 3.10.11

## 실행 방법

1. 가상환경 생성 및 활성화
    ```bash
    python -m venv venv
    source venv/bin/activate
    ```

2. 라이브러리 설치
    ```bash
    pip install --upgrade pip
    pip install -r requirements.txt
    ```

3. 코드 실행
    ```bash
    python scratch_nn.py
    ```

## 결과 예시

학습 과정에서 손실(loss)이 출력되고, 마지막에 XOR 문제에 대한 예측 결과가 출력됩니다.

## 결과
❯ python scratch_nn.py
Epoch 0, Loss: 0.2558
Epoch 1000, Loss: 0.2494
Epoch 2000, Loss: 0.2454
Epoch 3000, Loss: 0.2047
Epoch 4000, Loss: 0.1532
Epoch 5000, Loss: 0.1387
Epoch 6000, Loss: 0.1336
Epoch 7000, Loss: 0.1312
Epoch 8000, Loss: 0.1297
Epoch 9000, Loss: 0.1288
예측 결과:
[[0.05300868]
 [0.49554213]
 [0.95091319]
 [0.50319888]]

## 결과 설명
학습 과정 출력
Epoch 0, Loss: 0.2558 ~ Epoch 9000, Loss: 0.1288
→ 에폭이 증가할수록 손실(loss)이 점점 감소하고 있습니다.
→ 신경망이 XOR 문제를 점점 더 잘 학습하고 있다는 의미입니다.

예측 결과
각 행은 XOR 입력값에 대한 신경망의 출력(예측값)입니다.
0에 가까우면 False, 1에 가까우면 True로 해석할 수 있습니다.

입력  실제값  예측값	해석
0,0   0	    0.05	0에 가까움
0,1	  1	    0.50	1에 가까움
1,0	  1	    0.95	1에 가까움
1,1	  0	    0.50	0.5에 가까움

1,0 입력에 대해 0.95로 거의 1에 가까운 값을 예측하고 있습니다.
0,0 입력에 대해 0.05로 거의 0에 가까운 값을 예측하고 있습니다.
0,1과 1,1은 0.5 근처로, 완벽하게 구분하지는 못했지만 어느 정도 패턴을 학습했습니다.

결론
신경망이 XOR 문제의 패턴을 어느 정도 학습했으나, 은닉층 노드 수, 학습률, 에폭 등을 조정하면 더 정확한 결과를 얻을 수 있습니다.
XOR 문제는 비선형 분류 문제이기 때문에, 신경망 구조가 충분히 복잡해야 완벽하게 학습할 수 있습니다.
추가로 성능을 높이고 싶다면 hidden_size를 늘리거나 epochs를 증가시켜보세요!


## 참고

- numpy만 사용하여 신경망의 기본 원리를 익힐 수 있습니다.
- 더 복잡한 문제나 구조로 확장해보고 싶다면 hidden_size, epochs 등 하이퍼파라미터를 조정해보세요.