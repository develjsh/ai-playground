model = Sequential([

    # Conv2D: 이미지의 특징을 찾아내는 층 (합성곱 층)
    # filters=32  → 32개의 '필터(커널)'로 이미지를 스캔하여 32장의 특징맵 생성
    # kernel_size=(3,3) → 3x3 크기의 작은 창으로 이미지를 훑음
    # activation='relu' → 음수는 0으로 만들고 양수는 그대로 두는 함수
    #    - 이유: 학습 속도 빠르고, 경사소실(vanishing gradient) 문제를 줄임
    # padding='same' → 이미지를 훑은 후에도 가로·세로 크기를 줄이지 않음
    #    - 방법: 가장자리에 0을 채워서 필터가 끝부분까지 계산 가능하게 함
    # input_shape → 첫 층에서만 지정, (높이, 너비, 채널 수)로 이미지 크기 명시
    Conv2D(32, (3,3), activation='relu', padding='same', 
           input_shape=(image_height, image_width, image_channel)),

    # BatchNormalization: 층의 출력을 평균 0, 표준편차 1 근처로 맞춰줌
    # 장점: 학습 안정화, 더 큰 학습률 가능, 과적합 약간 방지
    BatchNormalization(),

    # 두 번째 합성곱 층: 첫 Conv2D에서 찾은 특징(선, 점 등)을 조합하여
    # 더 복잡한 패턴(모서리, 곡선 등)을 학습
    Conv2D(32, (3,3), activation='relu', padding='same'),

    # 정규화 다시 적용 → 값의 폭을 일정하게 유지해 학습 효율을 높임
    BatchNormalization(),

    # MaxPooling: 특징맵의 크기를 절반으로 줄임
    # (2,2) → 2x2 영역에서 가장 큰 값만 남김
    # 효과: 계산량 감소, 중요한 특징만 남김, 위치 변화에 강해짐
    MaxPool2D((2,2)),

    # Dropout(0.25): 학습 시 25%의 노드를 랜덤하게 꺼서 과적합 방지
    # 의미: 특정 노드에만 의존하지 않고, 다양한 경로로 학습하게 만듦
    Dropout(0.25),
    
    # 두 번째 블록 시작: 필터 수를 64로 늘려서 더 다양한 패턴을 학습
    Conv2D(64, (3,3), activation='relu', padding='same'),
    BatchNormalization(),
    Conv2D(64, (3,3), activation='relu', padding='same'),
    BatchNormalization(),
    MaxPool2D((2,2)),
    Dropout(0.25),
    
    # 세 번째 블록: 필터 수 128 → 더 복잡하고 고차원적인 패턴 학습
    # 예: 사물의 일부분, 질감(texture) 등
    Conv2D(128, (3,3), activation='relu', padding='same'),
    BatchNormalization(),
    Conv2D(128, (3,3), activation='relu', padding='same'),
    BatchNormalization(),
    MaxPool2D((2,2)),
    Dropout(0.25),
    
    # Flatten: 3차원 데이터(높이, 너비, 채널)를 1차원 벡터로 펼침
    # 목적: Dense 층에 넣어 분류가 가능하도록 만듦
    Flatten(),

    # Dense(512): Fully Connected Layer
    # 512개의 노드로 앞에서 추출한 특징을 종합해 판단
    # activation='relu' → 비선형성을 추가해 더 복잡한 패턴 학습 가능
    Dense(512, activation='relu'),

    # 정규화로 학습 안정화
    BatchNormalization(),

    # Dropout(0.5): 절반의 노드를 꺼서 과적합 방지 (더 강하게 적용)
    Dropout(0.5),

    # 최종 출력층: 43개의 노드 → 43개의 클래스 중 하나를 예측
    # activation='softmax' → 각 클래스에 대한 확률(0~1)을 출력하고 합은 1
    Dense(43, activation='softmax')
])

